{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy Text Similarity\n",
    "For text similarity, Spacy uses <b>word vectors</b> which was generated using Word2Vec models and <b>Cosine Similarity</b><br>\n",
    "For similarity, you can use :<br>\n",
    "1. Doc.similarity()\n",
    "2. Span.similarity()\n",
    "3. Token.similarity()\n",
    "<br>\n",
    "\n",
    "### Models available in Spacy are:\n",
    "- en_core_web_md (medium model)\n",
    "- en_core_web_lg (large model)\n",
    "- en_core_web_sm (small model) but not useful for text similarity\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"I like pasta\")\n",
    "token1 = doc1[2]\n",
    "doc2 = nlp(\"I like pizza\")\n",
    "token2 = doc2[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of the word pasta: [ 3.4587069  -5.1740785   1.5724678  -1.8150723   0.16870703 -1.0707431\n",
      "  4.2217684  -2.3746052  -4.827319    0.8752275  -1.0055934   1.2087524\n",
      " -0.49629104 -2.0868046   2.2549772  -1.6175449   1.9484265   1.0280021\n",
      " -0.44205624  1.2065959  -1.0452871  -4.4737735  -1.4106083   3.5614092\n",
      " -0.03724515 -0.70621526  1.6226947   1.546504    2.4825149   1.8595277\n",
      "  0.97728765 -2.322699    0.22202742 -0.99675757  0.2517177   1.0331284\n",
      "  0.019719   -0.6510774  -4.033538   -1.8552463  -2.125887    3.2676394\n",
      "  0.07941335 -1.8486612  -1.7704881  -0.7598312  -2.0591888  -4.144084\n",
      " -3.9161177  -1.5054088  -4.325083    0.29423118 -2.2109983  -1.753673\n",
      " -1.811351   -0.59585094  2.7309854  -2.30828     0.02852792  2.5986023\n",
      "  0.32365662  4.0930204   4.827987   -0.9883788   1.944063    2.099637\n",
      "  1.7788304  -2.1225457  -0.76004636  1.2609104  -0.243267   -2.2987692\n",
      "  3.9465563   2.1220016  -1.0930598   4.6695375  -0.3734905   1.9006069\n",
      " -2.6517713   1.3784261   2.0190027   2.1771243  -3.8441124   4.109814\n",
      "  3.4657788  -0.50429803 -0.23436898  1.831713    5.9491653   1.2257491\n",
      "  4.89603    -2.7441773  -3.8372033  -0.9691425  -2.067986    0.8164267 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Vector of the word %s: %s\"%(doc1[2],str(doc1[2].vector)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word similarity between 'pasta' and 'pizza' is '7.404463e-01'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "word_sim_score = token1.similarity(token2)\n",
    "print(\"word similarity between '%s' and '%s' is '%e'\"%(token1,token2,word_sim_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between doc1 and doc2: 0.9119401819026696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "sim_score = doc1.similarity(doc2)\n",
    "print(\"Similarity between doc1 and doc2:\", sim_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### similarity between the token and doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between the token 'pasta' and doc 'I like pasta' is 5.976120e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "tokenDoc_sim_score= doc1.similarity(token1)\n",
    "print (\"similarity between the token '%s' and doc '%s' is %e\"%(token1,doc1,tokenDoc_sim_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
